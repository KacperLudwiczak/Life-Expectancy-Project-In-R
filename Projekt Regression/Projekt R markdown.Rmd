---
title: "Projekt R markdown"
author: "Kacper Ludwiczak"
date: "2023-03-10"
output:
  word_document: default
  pdf_document: default
---

# Regression Model Projekt - Kacper Ludwiczak, 221303

## Temat - Kształtowanie się oczekiwanej długości życia dla większości państw świata na podstawie modelu regresji i czynniki wpływające na jego wysokość.

Zaczynając projekt pracowałem na danych związanych z nowoczesnymi technologiami. 
Dokonałem czyszczenia danych, obliczeń w excelu oraz obliczeń w języku R.
Projekty znajdują się pod nazwą “Stary projekt - Reggresion Models”, “Stary projekt – Zestawienie", “Stary projekt w R”. 
Jednakże stwierdziłem, że wyniki nie są zadowalające i porzuciłem ten projekt.

Następnie zacząłem prace nad tym modelem. Dane pozyskałem ze strony kaggle.com. 
Według strony dane pochodzą ze strony internetowej WHO i ONZ z pomocą Deeksha Russella i Duana Wanga. 
Dane dotyczą większości państw świata, ich różnych zbiorów informacji, np. Długość życia. 
Plik z oryginałem danych jest pod nazwą “Life Expectancy Data”.

[Link do strony z oryginalnymi danymi](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who?resource=download)


Po pierwsze chciałem skupić się na próbie 30 krajów. 
Wybrałem zatem 30 krajów, metodą losową.
Dane obliczyłem zarówno w excelu jak i w języku R. 
Dane i obliczenia znajdują się w pliku “Projekt w R próba” oraz “Projekt w Excel próba”.

Uznałem, że lepszym pomysłem będzie stworzenie modelu z większości krajów na jakich dano było mi pracować. 
Zacząłem od pozostawienia tylko krajów z 2015 jako najbardziej aktualnych z danej bazy. 
Dane są pod nazwą “Dane z 2015”. Następnie zamieniłem dane za pomocą funkcji “Tekst jako kolumny”. 
Usunąłem kolumny “Year”, “Status”, ponieważ kolumny są mi niepotrzebne. 
Usunąłem kolumny “Alcohol”, “percentage expenditure”, “Total expenditure”, ponieważ były zauważające braki danych. 
Usunąłem kolumny “BMI”, “HIV/AIDS”, “thinness 1-19 years”, “thinness 5-9 years”, “Schooling”, ponieważ pojawiła mi się pewna anomalia. 
Podczas zamiany na kolumny niektóre dane są formacie daty, po zamienieniu ich na liczby pojawiały się błędne liczby. 
Również nie które liczby zamienione automatycznie są błędne. 
Po wielu nieudanych próbach rozwiązania tego problemu, dokonałem eliminacji tych kolumn. 
Również musiałem dokonać zamiany kropek na przecinki w liczbach oraz wypełnić puste pola średnią z reszty kolumny. 
Dane znajdują się w pliku “Dane zrobione”. 
Również stworzyłem osobny plik dla importowania do RStudio, pod nazwą “Dane do R”.

### Szczegóły dotyczące danych:
* Country - Kraj
* Year - Rok
* Status - Stan rozwinięty lub rozwijający się
* Life expectancy - Oczekiwana długość życia w latach
* Adult Mortality - Wskaźniki śmiertelności dorosłych obu płci (prawdopodobieństwo śmierci w wieku od 15 do 60 lat na 1000 mieszkańców)
* Infant deaths - Liczba zgonów niemowląt na 1000 ludności
* Alcohol - Spożycie alkoholu na mieszkańca (15+) (w litrach czystego alkoholu)
* Hepatitis B - Zasięg szczepień przeciw wirusowemu zapaleniu wątroby typu B (HepB) wśród 1-latków (%)
* Measles – Odra, liczba zgłoszonych przypadków na 1000 ludności
* BMI - Średni wskaźnik masy ciała całej populacji
* Under-five deaths - Liczba zgonów poniżej piątego roku życia na 1000 mieszkańców
* Polio - Zasięg szczepień przeciw polio (Pol3) wśród 1-latków (%)
* Total expenditure - Wydatki sektora instytucji rządowych i samorządowych na zdrowie jako odsetek wydatków sektora instytucji rządowych i samorządowych ogółem (%)
* Diphtheria - Odsetek szczepień przeciwko anatoksynie błonicy i tężcowi oraz krztuścowi (DTP3) wśród 1-latków (%)
* HIV/AIDS - Zgony na 1000 żywych urodzeń HIV/AIDS (0-4 lata)
* GDP - Produkt Krajowy Brutto per capita (w USD)
* Population - Ludność kraju
* Thinness 1-19 years - Rozpowszechnienie szczupłości wśród dzieci i młodzieży w wieku od 10 do 19 lat (%)
* Thinness 5-9 years - Występowanie szczupłości wśród dzieci w wieku od 5 do 9 lat (%)
* Income - Wskaźnik rozwoju społecznego pod względem struktury dochodów zasobów (wskaźnik w zakresie od 0 do 1)
* Schooling- Liczba lat nauki (lata)

### Projekt w RStudio jest pod nazwą “Projekt R markdown”


Zainstalowałem pakiet “readxl”, oraz uruchomiłem go przez funkcje “library”.
```{r}
library(readxl)
```


Zainstalowałem pakiet “rmarkdown”, oraz uruchomiłem go przez funkcje “library”.
```{r}
library(rmarkdown)
```



Kod wczytuje plik excel "Dane do R.xlsx" i zapisuje jego zawartość w zmiennej "Dane". Następnie
wyświetla zawartość tej zmiennej za pomocą funkcji "View()", wyświetla nazwy kolumn danych za
pomocą funkcji "names()", a na końcu wyświetla wartości kolumny "Life expectancy" za pomocą
funkcji "print()".
```{r}
Dane <-  read_excel("C:/Users/Kacper/Desktop/Projekt Regression/Dane do R.xlsx")
View(Dane)
names(Dane)
print(Dane$"Life expectancy" )
```


Tutaj za pomocą funkcji “colnames” dokonałem zmiany nazw kolumn w celu szybszej pracy w
dalszych etapach.
```{r}
colnames(Dane)<-c("Life","Adult_M","Infant_D","H_B","Measles","Under_D","Polio","Dipht","GDP","Popl","Income")
```


Użyłem funkcji “plot” w celu zobaczeniu na wykresie dane z kolumny “Life”. Kolumna “Life” zostaje
moją zmienną zależną, natomiast reszta kolumn zmiennymi niezależnymi.
```{r}
plot(Dane$"Life")
```


Sprawdziłem następujące wartości danych:
* Minimalna wartość = 51.00
* Pierwszy kwartal = 65.85
* Mediana = 73.95
* Średnia = 71.72
* Trzeci kwartal = 76.97
* Maksymalna wartość = 88.00
, dla zmiennej zależnej.
```{r}
summary(Dane$"Life" )
```


W celu zobrazowania graficznego użyłem funkcji “hist”. Według tego można zauważyć dominacje wartości w przedziale od 70 do 80.
```{r}
hist(Dane$"Life" )
```


Za pomocą funkcji “cor” przedstawiłem korelacje wszystkich zmiennych. Im dana liczba jest większa
tym większa jest korelacja między odpowiadającymi danymi w wierszu i kolumnie.
Można z niej ustalić, że korelacja między zmienną zależną “Life” a zmienną:
* “Adult_M” jest duża ujemnie
* “Infant_D” jest bardzo mała ujemnie
* “H_B” jest mała dodatnio
* “Measles” jest bardzo mała ujemnie
* “Under_D” jest bardzo mała ujemnie
* “Polio” jest średnia dodatnio
* “Dipht” jest średnia dodatnio
* “GDP” jest mała dodatnio
* “Popl” jest bardzo mała ujemnie
* “Income” jest bardzo mała ujemnie
```{r}
cor(Dane)
```


Kod ten oblicza korelację między kolumnami w obiekcie "Dane", z wyjątkiem pierwszej kolumny,
która jest pomijana za pomocą wyrażenia "[, -1]". Jest to kolumna “Life”. Funkcja "cor" oblicza
korelację Pearsona, czyli stopień zależności liniowej między dwoma zmiennymi. Wynik jest następnie
zaokrąglany do trzech miejsc po przecinku za pomocą funkcji "round".
```{r}
round(cor(Dane[,-1]),3)
```


Kod ten tworzy macierz z danych zawartych w obiekcie "Dane". Wiersze z obiektu "Dane" są
wczytywane za pomocą wyrażenia "[, -1]", co oznacza, że pierwsza kolumna jest pomijana. Jest to
kolumna “Life”. Następnie dane są konwertowane na macierz za pomocą funkcji "as.matrix".
Ostatecznie macierz jest przypisywana do obiektu "matrix".
```{r}
matrix <- as.matrix(Dane[,-1])
```


Kod oblicza własne wartości i wektory dla macierzy "matrix". Macierz jest najpierw transponowana
za pomocą funkcji "t", a następnie mnożona przez siebie za pomocą operatora "%*%", co daje
macierz kowariancji. Otrzymaną macierz kowariancji jest analizowana przez funkcję "eigen", która
oblicza własne wartości i wektory. Wynik jest przypisywany do obiektu "matrix_eigen". Dzięki temu
mogę zobaczyć własne wartości macierzy
```{r}
matrix_eigen <- eigen(t(matrix) %*% matrix)
matrix_eigen$val
```


Kod wylicza pierwiastek kwadratowy elementów ilorazu dwóch wektorów za pomocą “sqrt”, 
“matrix_eigen$val[1]” jest pierwszym elementem wektora “matrix_eigen$val”, a
“matrix_eigen$val” jest całym wektorem. Dostając następujące wyniki. Wyniki powyżej 30
wskazują na brak współliniowości.
W moim przypadku można zauważyć, że współliniowość nie występuje. Na tym etapie można
wykluczyć jako by mój model był dobrym modelem.
```{r}
sqrt(matrix_eigen$val[1]/matrix_eigen$val)
```


Sprawdziłem na wykresie jaka jest korelacje zmiennej zależnej i zmiennej “Adult_M” w postaci
graficznej.
Tutaj przetestowałem funkcje “lm” za pomocą stworzenia modelu prostej regresji liniowej z użyciem
jednej zmiennej niezależnej. 
Funkcja “abline” umożliwiła mi dodanie niebieskiej linii regresji, która najdokładniej próbuje
dopasować się do istniejących danych. Można zauważyć, że linia jest przekrzywiona w dół po stronie
lewej, wynika to z pojawiających się wartości odstających, poniżej wartości 100 dla zmiennej
niezależnej.
```{r}
plot(Dane$"Life"~Dane$"Adult_M")
SimpleModel<- lm(Dane$"Life"~Dane$"Adult_M")
abline(SimpleModel$coef,col="blue")
```


Wynik p-value wyszedł bardzo dobry. Jednakże wartość R-squared zbyt
mała.
```{r}
summary(SimpleModel)
```


Stworzenie pierwszego modelu. Używam metody “Backward” ręcznie. Eliminując zmienne o
najwyższym wskaźniku p-value, tak długo aż model będzie zadawalający. Zakładam dla modelu, że
poziom p-value poniżej 0.05 jest odpowiedni.

Podsumowaniem modelu regresji liniowej wygląda następująco. Zawiera on informacje na temat
tego, jak dobrze modelem można wyjaśnić zmienną zależną (Life), korzystając z 7 zmiennych
objaśniających (Adult_M, Infant_D, H_B, Measles, Under_D, Polio, Dipht, GDP, Popl,
Income).
Sekcja "Residuals" pokazuje rozkład reszt modelu regresji liniowej, czyli różnic między wartościami
faktycznymi a wartościami przewidywanymi. "Min", "1Q", "Median", "3Q", i "Max" to odpowiednio
najmniejsza, pierwszy kwartyl, medianę, trzeci kwartyl, i największą wartość reszt.
Sekcja "Coefficients" pokazuje wartości współczynników regresji dla każdej zmiennej objaśniającej,
wraz z błędem standardowym i wartością statystyki t. Wartość p dla każdej zmiennej określa, czy jest
ona istotna statystycznie (p < 0,05 oznacza, że zmienna jest istotna).
Wartość "Residual standard error" to średni kwadrat błędu reszty. "Multiple R-squared" to
współczynnik determinacji, który określa, jak dobrze modelem można wyjaśnić zmienną zależną.
Wartość R-kwadratu zawsze znajduje się w zakresie od 0 do 1, a wartość bliska 1 oznacza dobre
dopasowanie modelu. "Adjusted R-squared" to współczynnik determinacji uwzględniający liczbę
zmiennych objaśniających. Wartość "F-statistic" i "p-value" służą do testowania hipotezy zerowej, że
wszystkie współczynniki regresji są równe 0.
```{r}
Model <- lm(Life~Adult_M+Infant_D+H_B+Measles+Under_D+Polio+Dipht+GDP+Popl+Income,data=Dane)
summary(Model)

```


W pierwszym modelu największy poziom p-value miała kolumna “Measles”. W drugim modelu już
się nie pojawiła.
```{r}
Model2 <- lm(Life~Adult_M+Infant_D+H_B+Under_D+Polio+Dipht+GDP+Popl+Income,data=Dane)
summary(Model2)
```


W drugim modelu największy poziom p-value miała kolumna “H_B”. W trzecim modelu już się nie
pojawiła
```{r}
Model3 <- lm(Life~Adult_M+Infant_D+Under_D+Polio+Dipht+GDP+Popl+Income,data=Dane)
summary(Model3)
```


W trzecim modelu największy poziom p-value miała kolumna “Income”. W czwartym modelu już się
nie pojawiła.
```{r}
Model4 <- lm(Life~Adult_M+Infant_D+Under_D+Polio+Dipht+GDP+Popl,data=Dane)
summary(Model4)
```


W czwartym modelu największy poziom p-value miała kolumna “Popl”. W piątym modelu już się nie
pojawiła.
```{r}
Model5 <- lm(Life~Adult_M+Infant_D+Under_D+Polio+Dipht+GDP,data=Dane)
summary(Model5)
```


W piątym modelu po usunięciu kolumny “Popl”, nastąpił duży wzrost wartości p-value dla kolumny
“Under_D” oraz “Polio”. Jest efekt niepożądany dla mojego modelu, dlatego wybranym modelem
zostaje model czwarty. Pomimo wartości p-value dla kolumny “Popl” w okolicy 0.08. Również
poziom R-squared wynosi 0.7229, możemy interpretować to jako dobry model, choć na granicy złego
(zmienność oczekiwanej długości życia jest wyjaśniony w 72% przez model). 
Dodatkowo Adjusted Rsquared jest na poziomie 0.7118, jest to najlepszy wynik ze wszystkich pięciu policzonych.
```{r}
Model <- lm(Life~Adult_M+Infant_D+Under_D+Polio+Dipht+GDP+Popl,data=Dane)
summary(Model)
```


W celu potwierdzenia wybrania dobrego modelu, użyłem funkcji “step” za równo direction
“backward” jak i “both”. Obie funkcje dały mi wynik identyczny dla mojego. Kod tworzy nowy model
regresji liniowej "Model_nowy_backward" przy użyciu procedury backward selection. Procedura ta
polega na usuwaniu najmniej istotnych zmiennych objaśniających, aż pozostaną tylko te, które są
istotne statystycznie. Na początku tworzony jest pełny model regresji liniowej. Następnie jest on
przekształcany za pomocą funkcji "step" z argumentem "direction = 'backward'". W końcowym kroku
wyświetlane jest podsumowanie modelu "Model_nowy_backward", a następnie "Model_nowy" jest
ustawiany na "Model_nowy_backward" i wyświetlany jest ponownie podsumowanie modelu.
```{r}
Model_backward<-step(lm(Life~Adult_M+Infant_D+H_B+Measles+Under_D+Polio+Dipht+GDP+Popl+Income,data=Dane),direction="backward")
summary(Model_backward)
```

```{r}
Model_both<-step(lm(Life~Adult_M+Infant_D+H_B+Measles+Under_D+Polio+Dipht+GDP+Popl+Income,data=Dane),direction="both")
summary(Model_both) 
```


Kodu przedstawia analizę reszt statystycznych (residuals) na podstawie oszacowania opartego na
estymatorach.
* "RS <- rstudent(Model)" - definiuje nową zmienną "RS" jako wartości R-student reszt modelu.
* "plot(RS, ylab="R-Student residual", main="R-Student residual")" - tworzy wykres R-Student reszt.
* "RS[abs(RS)==max(abs(RS))]" - znajduje największą wartość absolutną w zmiennej "RS".
* "dim(Dane)" - zwraca wymiary macierzy "Dane".
* "dim(Dane)[1]" - zwraca liczbę wierszy macierzy "Dane".
* "0.05/dim(Dane)[1]*2" - oblicza prawdopodobieństwo dwustronnego testu.
* "dim(Dane)[1]-4-1" - oblicza stopień swobody.
* "qt(0.05/(dim(Dane)[1]*2),(dim(Dane)[1]-4-1))" - oblicza kwantyl dla dwustronnego testu.
* "(-abs(RS[abs(RS)==max(abs(RS))])<qt(0.05/(dim(Dane)[1]*2),(dim(Dane)[1]-4-1)))" - sprawdza, czy
największa wartość absolutna w "RS" jest mniejsza niż kwantyl dwustronnego testu.

Wynik jest “TRUE”, czyli największa wartość absolutna w "RS" jest mniejsza niż kwantyl
dwustronnego testu.
```{r}
(RS <- rstudent(Model))
```


Przedstawienie na wykresie 
```{r}
plot(RS,ylab="R-Student residual",main="R-Student residual")
```


Uzyskanie wartości odstających.
```{r}
RS[abs(RS)==max(abs(RS))]
```

```{r}
dim(Dane)
dim(Dane)[1]
0.05/dim(Dane)[1]*2
dim(Dane)[1]-4-1
qt(0.05/(dim(Dane)[1]*2),(dim(Dane)[1]-4-1))
```

```{r}
(-abs(RS[abs(RS)==max(abs(RS))])<qt(0.05/(dim(Dane)[1]*2),(dim(Dane)[1]-4-1)))
```


Dzięki odległości cooka, mogę usunąć wartości odstające i stworzyć nowy model o nazwie
“Model_no_outliers”. Kod wykorzystuje funkcję cooks.distance do obliczenia odległości Cooka
dla każdego punktu danych. Odległość Cooka jest miarą, jak bardzo punkt danych wpływa na wynik
modelu regresji liniowej. Wartość odległości Cooka jest wyznaczana jako iloczyn między zmienną
zależną (Life) i skorygowaną estymatą modelu bez tego punktu danych. Wartości odległości Cooka
powyżej 1 są uważane za "outliers", tj. punkty danych, które mają nieproporcjonalnie duży wpływ na
wynik modelu. Następnie wykonywane jest wykreślenie wartości odległości Cooka, a następnie
tworze nowy model regresji liniowej bez punktów danych, które są outliers. W rezultacie, wynik
końcowy jest wynikiem modelu regresji liniowej bez wartości odstających.
```{r}
(cooks_dis <- cooks.distance(Model))
```


Tworzenie wykresu
```{r}
plot(cooks_dis,ylab="Cooks distances")
```


“Model_no_outliers” ma lepsze wyniki niż Model. 
```{r}
Model_no_outliers <-lm(Life~Adult_M+Infant_D+Under_D+Polio+Dipht+GDP+Popl,data=Dane,subset=(cooks_dis<max(cooks_dis)))
summary(Model_no_outliers)
```


Kod tworzy wykres diagnostycznych reszt dla modelu statystycznego.
* "par(mfrow=c(2,1))" - ustawia parametr okna, aby rysować dwa wykresy na jednej stronie.
* "plot(Model$res, ylab="Residuals", main="Index plot of residuals")" - tworzy wykres indexu reszt dla modelu "Model".
* "abline(h=0, col="red")" - dodaje linie na wykresie, reprezentującą wartość 0, w kolorze czerwonym.
* "plot(Model$fit, Model$res, xlab="Fitted", ylab="Residuals")" - tworzy wykres reszt, gdzie na osi x jest "Fitted", a na osi y jest "Residuals".
* "abline(h=0, col="red")" - dodaje linie na wykresie, reprezentującą wartość 0, w kolorze czerwonym.
* "plot(Model_no_outliers$res, ylab="Residuals", main="Index plot of residuals")" - tworzy wykres indexu reszt dla modelu "Model_no_outliers".
* "abline(h=0, col="red")" - dodaje linie na wykresie, reprezentującą wartość 0, w kolorze czerwonym.
* "plot(Model_no_outliers$fit, Model_no_outliers$res, xlab="Fitted", ylab="Residuals")" - tworzy wykres skojarzony reszt, gdzie na osi x jest "Fitted", a na osi y jest "Residuals", dla modelu "Model_no_outliers".
* "abline(h=0, col="red")" - dodaje linie na wykresie, reprezentującą wartość 0, w kolorze czerwonym
```{r}
par(mfrow=c(2,1))
plot(Model$res,ylab="Residuals",main="Index plot of residuals")
abline(h=0,col="red")
plot(Model$fit,Model$res,xlab="Fitted",ylab="Residuals")
abline(h=0,col="red")
```


```{r}
par(mfrow=c(2,1))
plot(Model_no_outliers$res,ylab="Residuals",main="Index plot of residuals")
abline(h=0,col="red")
plot(Model_no_outliers$fit,Model_no_outliers$res,xlab="Fitted",ylab="Residuals")
abline(h=0,col="red")
```


Test rozkładu normalnego zacząłem od graficznego przedstawienia wszystkich zmiennych w modelu.
Za pomocą funkcji “boxplot” oraz “qqnorm”.
Kod przedstawia.
* "boxplot(Dane$Life)" - rysuje wykres typu boxplot, który pokazuje statystyki centralne i rozrzut danych dla zmiennej "Life".
* "qqnorm(Dane$"Life" )" - rysuje wykres typu Q-Q plot, który pokazuje, jak bardzo dane odpowiadają rozkładowi normalnemu.
* "qqline(Dane$"Life" )" - dodaje linię do wykresu typu Q-Q plot, która pokazuje, jak dane powinny odpowiadać rozkładowi normalnemu.

Jeśli dane są zgodne z rozkładem normalnym, to na wykresie typu Q-Q plot powinny być one
rozłożone wokół linii. Jeśli nie są, oznacza to, że dane nie odpowiadają rozkładowi normalnemu.
Wykres pudełkowy składa się z osi. Nad osią umieszczony jest prostokąt (pudełko), którego lewy bok
jest wyznaczony przez pierwszy kwartyl, zaś prawy bok przez trzeci kwartyl. Szerokość pudełka
odpowiada wartości rozstępu ćwiartkowego. Wewnątrz prostokąta znajduje się pionowa linia,
określająca wartość mediany.
W pierwszym przykładzie można zauważyć, że dane z kolumny “Life” całkiem dobrze wypadają na
rozkładzie normalnym.
```{r}
boxplot(Dane$Life)
```


```{r}
qqnorm(Dane$"Life" )
qqline(Dane$"Life" )
```


```{r}
boxplot(Dane$Adult_M)
```


```{r}
qqnorm(Dane$"Adult_M" )
qqline(Dane$"Adult_M" )
```


```{r}
boxplot(Dane$Infant_D)
```


```{r}
qqnorm(Dane$"Infant_D")
qqline(Dane$"Infant_D")
```


```{r}
boxplot(Dane$Under_D)
```


```{r}
qqnorm(Dane$"Under_D")
qqline(Dane$"Under_D")
```


```{r}
boxplot(Dane$Polio)
```


```{r}
qqnorm(Dane$"Polio")
qqline(Dane$"Polio")
```

```{r}
boxplot(Dane$Dipht)
```


```{r}
qqnorm(Dane$"Dipht")
qqline(Dane$"Dipht")
```


```{r}
boxplot(Dane$GDP)
```


```{r}
qqnorm(Dane$"GDP")
qqline(Dane$"GDP")
```


```{r}
boxplot(Dane$Popl)
```


```{r}
qqnorm(Dane$"Popl")
qqline(Dane$"Popl") 
```


Również przedstawiłem graficznie to samo za pomocą pakietu “ggpubr”, oraz funkcji “ggqqplot”.
Wykres Q-Q jest rysowany między daną próbą a rozkładem normalnym. Wykreślana jest również 45-
stopniowa linia odniesienia, aby ocenić, jak bliskie są wartości próbki rozkładowi normalnemu.
```{r}
library("ggpubr")
```

```{r}
ggqqplot(Dane$Life, ylab = "Life")
```


```{r}
ggqqplot(Dane$Adult_M, ylab = "Adult_M")
```


```{r}
ggqqplot(Dane$Infant_D, ylab = "Infant_D")
```


```{r}
ggqqplot(Dane$Under_D, ylab = "Under_D")
```


```{r}
ggqqplot(Dane$Polio, ylab = "Polio")
```


```{r}
ggqqplot(Dane$Dipht, ylab = "Dipht")
```


```{r}
ggqqplot(Dane$GDP, ylab = "GDP")
```


```{r}
ggqqplot(Dane$Popl, ylab = "Popl")
```


Przedstawienie na wykresie rozkładu normlanego modeli “Model” oraz “Model_no_outliers”.
Kod pokazuje wizualizację danych i sprawdza, czy reszty regresji są zgodne z rozkładem normalnym.
* "par(mfrow=c(1,1))" - oznacza, że na każdej stronie wyników będzie tylko jeden wykres.
* "qqnorm(Model$res,ylab="Residuals")" - rysuje wykres typu Q-Q plot dla reszt regresji Model, z opisem osi y jako "Residuals".
* "qqline(Model$res, col="blue")" - dodaje linię do wykresu typu Q-Q plot, która pokazuje, jak dane powinny odpowiadać rozkładowi normalnemu. Kolor linii to niebieski.
```{r}
par(mfrow=c(1,1))
qqnorm(Model$res,ylab="Residuals")
qqline(Model$res, col="blue")
```


Przedstawienie na wykresie rozkładu normlanego modeli “Model” oraz “Model_no_outliers” z
użyciem funkcji “rstudent”.
* "qqnorm(Model_no_outliers$res,ylab="Residuals")" - rysuje wykres typu Q-Q plot dla reszt regresji Model_no_outliers, z opisem osi y jako "Residuals".
* "qqline(Model_no_outliers$res, col="blue")" - dodaje linię do wykresu typu Q-Q plot, która pokazuje, jak dane powinny odpowiadać rozkładowi normalnemu. Kolor linii to niebieski.
* "qqnorm(rstudent(Model),ylab="Studentized residuals")" - rysuje wykres typu Q-Q plot dla studentyzowanych reszt regresji Model, z opisem osi y jako "Studentized residuals".
* "abline(0,1)" - dodaje prostą do wykresu typu Q-Q plot, która pokazuje, jak dane powinny odpowiadać rozkładowi normalnemu.
* "qqnorm(rstudent(Model_no_outliers),ylab="Studentized residuals")" - rysuje wykres typu Q-Q plot dla studentyzowanych reszt regresji Model_no_outliers, z opisem osi y jako "Studentized residuals".
* "abline(0,1)" - dodaje prostą do wykresu typu Q-Q plot, która pokazuje, jak dane powinny odpowiadać rozkładowi normalnemu.
```{r}
par(mfrow=c(1,1))
qqnorm(Model_no_outliers$res,ylab="Residuals")
qqline(Model_no_outliers$res, col="blue")
```


```{r}
qqnorm(rstudent(Model),ylab="Studentized residuals")
abline(0,1)
```


```{r}
qqnorm(rstudent(Model_no_outliers),ylab="Studentized residuals")
abline(0,1)
```


W celu sprawdzenia rozkładu normlanego użyje testu Shapiro-Wilka.
P-value w teście Shapiro-Wilka jest miarą siły dowodu przeciwko hipotezie, że dane pochodzą z
rozkładu normalnego. Im mniejsze p-value, tym mocniejszy jest dowód przeciwko hipotezie
normalności.
Jeśli p-value jest mniejsze niż poziom istotności (np. 0,05), to odrzucamy hipotezę normalności i
stwierdzamy, że dane nie pochodzą z rozkładu normalnego. W przeciwnym razie przyjmujemy
hipotezę normalności.
Za pomocą “shapiro.test” mogłem uzyskać następująće wyniki
* Dla modelu “Model” wynik wyszedł W = 0.97386, p-value = 0.001701. Poniżej 0,05 p-value
rozkład nie jest normalny.
* Dla modelu “Model2” wynik wyszedł W = 0.97416, p-value = 0.001852. Poniżej 0,05 p-value
rozkład nie jest normalny.
* Dla modelu “Model3” wynik wyszedł W = 0.97468, p-value = 0.002148. Poniżej 0,05 p-value
rozkład nie jest normalny.
* Dla modelu “Model4” wynik wyszedł W = 0.97386, p-value = 0.001701. Poniżej 0,05 p-value
rozkład nie jest normalny.
* Dla modelu “Model5” wynik wyszedł W = 0.97026, p-value = 0.0006324. Poniżej 0,05 p-value
rozkład nie jest normalny.
* Dla modelu “Model_no_outlires” wynik wyszedł W = 0.97233, p-value = 0.001155. Poniżej
0,05 p-value rozkład nie jest normalny.
Wszystkie modele uzyskały wynik p-value poniżej 0,05, co czynni je niepochodzących z rozkładu
normlanego. Jednocześnie wyniki są bardzo zbliżone. Nie zmieniam modelu, a modelem jest model
“Model4”.
```{r}
shapiro.test(Model$res)
```

```{r}
shapiro.test(Model2$res)
```

```{r}
shapiro.test(Model3$res)
```


```{r}
shapiro.test(Model4$res)
```


```{r}
shapiro.test(Model5$res)
```


```{r}
shapiro.test(Model_no_outliers$res)
```


Test niezależności
Kod ładuje bibliotekę "randtests" i wywołuje funkcję "runs.test" na zmiennej "Model$res" oraz
Model_no_outliers$res". Funkcja "runs.test" jest jednym z testów dla oceny losowości w sekwencji
wartości. Test jest wykonywany na “residulas” z modelu statystycznego.
Wynik testu przedstawia czy wartości "residuals” są losowe, czy są skorelowane.
Jeśli wartości danych byłyby losowe, można oczekiwać, że liczba ciągów wzrostów i spadków
wartości byłaby podobna. Jeśli natomiast wartości danych byłyby skorelowane, można oczekiwać, że
będzie więcej ciągów wzrostów niż spadków, lub na odwrót.
W obu przypadkach moje model są powyżej 0.05 p-value, oznacza to, że nie odrzucaja hipotezę
zerową i wartości są losowe.
```{r}
library(randtests)
```

```{r}
runs.test(Model$res)
```

```{r}
runs.test(Model_no_outliers$res)
```


Kod oznacza wykonanie analiz regresji dla zmiennych wyjaśniających w zbiorze danych Dane.
W pierwszej linijce tworzy się macierz explanatory z wykluczeniem pierwszej kolumny Dane.
Następnie tworzy się model regresji dla pierwszej kolumny explanatory jako zmiennej zależnej i
pozostałych kolumn explanatory jako zmiennych niezależnych. Podsumowanie modelu jest
wyświetlane za pomocą funkcji summary().
Wartość współczynnika determinacji dla tego modelu jest pobierana z jego podsumowania.
```{r}
explanatory<-as.matrix(Dane[,-1])
```

```{r}
summary(lm(explanatory[,1]~explanatory[,-1]))
```

```{r}
summary(lm(explanatory[,1]~explanatory[,-1]))$r.squared
```


W tej części kodu zaimportowana jest biblioteka “car” i wykonane jest obliczenie Variance Inflation
Factor (VIF) dla modelu “Model” automatycznie. VIF jest miarą multicollinearity (wzajemnej
korelacji) pomiędzy zmiennymi niezależnymi w modelu regresji. Wartość VIF powyżej 10 sugeruje
występowanie wzajemnej korelacji i konieczność usunięcia jednej z kolumn explanatory. W moim
modelu takimi wartościami są “Infant_D” oraz “Under_D”.
```{r}
library(car)
vif(Model)
```


Za pomocą “Model”, mogłem dostać współczynniki dla wszystkich zmiennych.
```{r}
Model$coefficients
```


Przykładowa interpretacja współczynnika dla “Adult_M”:
Jeśli zwiększymy oczekiwane prawdopodobieństwo śmierci między 15 a 60 rokiem życia na 1000
mieszkańców o rok, to oczekiwana długość życia w kraju zmniejszy się o 4,73 lata, przy założeniu
niezmienionych wartości pozostałych zmiennych objaśniających tzn. zgodnie z zasadą ceteris
Paribus.
Stworzyłem nowe zmienne do których przypisałem współczynniki. Dostając bety z odpowiadającymi
współczynnikami.
```{r}
beta_0<-Model$coefficients['(Intercept)']
beta_0
```

```{r}
beta_adultm<-Model$coefficients['Adult_M']
beta_adultm
```

```{r}
beta_infantd<-Model$coefficients['Infant_D']
beta_infantd
```

```{r}
beta_underd<-Model$coefficients['Under_D']
beta_underd
```

```{r}
beta_polio<-Model$coefficients['Polio']
beta_polio
```

```{r}
beta_dipht<-Model$coefficients['Dipht']
beta_dipht
```
```{r}
beta_gdp<-Model$coefficients['GDP']
beta_gdp
```


```{r}
beta_popl<-Model$coefficients['Popl']
beta_popl

```


Dzięki stworzeniu bet, mogę dokonać predykcji. Stworzyłem 3 różne predykcje z różnymi liczbami.
Przykładowo w “forecast” zakładając, że:
* “Adult Mortality” jest na poziomie 100
* “Infant deaths” jest na poziomie 56
* “Under-five deaths” jest na poziomie 80
* “Polio” jest na poziomie 70
* “Diphtheria” jest na poziomie 80
* “GDP” jest na poziomie 300
* “Population” jest na poziomie 10000000
Wynik oczekiwanej długości życia według modelu wynosi 71.54948.
```{r}
(forecast<-beta_0+beta_adultm*100+beta_infantd*56+beta_underd*80+beta_polio*70+beta_dipht*80+beta_gdp*300+beta_popl*10000000)
```

```{r}
(forecast2<-beta_0+beta_adultm*500+beta_infantd*86+beta_underd*90+beta_polio*73+beta_dipht*94+beta_gdp*456+beta_popl*9080000)
```

```{r}
(forecast3<-beta_0+beta_adultm*60+beta_infantd*47+beta_underd*52+beta_polio*64+beta_dipht*45+beta_gdp*291+beta_popl*13768000)
```


W już końcowym etapie projektu dostrzegłem możliwość innego wprowadzenia danych. Użyłem
sposobu zmiany danych w RStudio. Musiałem użyć nowego pakietu “tidyverse”, aby odczytało moje
dane w formacie “csv”. Tak dostałem dane z prawidłowym odczytem kolumn, które w excelu nie
działały, dzięki temu dostałem dostęp do danych, które bardzo mnie ciekawiły i chciałem użyć
wcześniej. Postanowiłem nie usuwać poprzedniej pracy w celu sprawozdania pracy i dostania
możliwych ciekawych wyników.
Instalacja pakietu i uruchomienie go, aby użyć funkcji “read_csv
```{r}
library(tidyverse)
```

Stworzenie nowego wektora z nową bazą danych, o nazwie “Dane_nowe”
```{r}
Dane_nowe <-  read_csv("C:/Users/Kacper/Desktop/Projekt Regression/Dane z 2015.csv")
View(Dane_nowe)
names(Dane_nowe)
```


Działania kodu:
Ładuje bibliotekę "dplyr", która zapewnia zestaw narzędzi do pracy z ramkami danych w R.
Używa biblioteki "dplyr" do modyfikowania ramki danych "Dane_nowe". Funkcja "select" jest
używana do wybierania kolumn z ramki danych, a argument "-c(Country, Year, Status, Alcohol,
percentage expenditure, Total expenditure)" jest używany, aby wykluczyć określone
kolumny z ramki danych. Rezultat jest przypisywany z powrotem do "Dane_nowe" za pomocą
operatora rury "%>%".
Wywołuje funkcję "View", aby wyświetlić zawartość zmodyfikowanej ramki danych "Dane_nowe" w
formacie tabeli.
Wywołuje funkcję "names", aby wyświetlić nazwy kolumn w zmodyfikowanej ramce danych
"Dane_nowe".
```{r}
library("dplyr")
Dane_nowe <- Dane_nowe %>% select(-c(Country, Year, Status, Alcohol, `percentage expenditure`, `Total expenditure`))
View(Dane_nowe)
names(Dane_nowe)
```


Przydzielanie nowych nazw kolumną.
```{r}
colnames(Dane_nowe)<-c("Life","Adult_M","Infant_D","H_B","Measles","BMI", "Under_D","Polio","Dipht","H/A", "GDP","Popl", "t_1-19", "t_5-9", "Income", "Schooling")
```


Działania kodu:
Tworzy nową kolumnę w ramce danych "Dane_nowe" o nazwie "H_B".
Używa funkcji "ifelse" do wypełnienia brakujących wartości (reprezentowanych przez "NA") w
kolumnie "H_B".
Jeśli wartość w danej komórce kolumny "H_B" jest "NA", oblicza się średnią wszystkich niebrakujących wartości w kolumnie "H_B" za pomocą funkcji "mean" z argumentem "na.rm = TRUE",
który usuwa brakujące wartości z obliczeń.
Jeśli wartość w danej komórce kolumny "H_B" nie jest "NA", wartość pozostaje niezmieniona.
Rezultat jest przypisywany z powrotem do kolumny "Dane_nowe$H_B".
```{r}
Dane_nowe$H_B = ifelse(is.na(Dane_nowe$H_B),
                       ave(Dane_nowe$H_B, FUN = function(x) mean(x, na.rm = TRUE)),
                       Dane_nowe$H_B)
```

Działania te są wykonywane na reszcie kolumn z brakującymi danymi.
```{r}
Dane_nowe$BMI = ifelse(is.na(Dane_nowe$BMI ),
                       ave(Dane_nowe$BMI , FUN = function(x) mean(x, na.rm = TRUE)),
                       Dane_nowe$BMI )
Dane_nowe$GDP = ifelse(is.na(Dane_nowe$GDP ),
                       ave(Dane_nowe$GDP  , FUN = function(x) mean(x, na.rm = TRUE)),
                       Dane_nowe$GDP  )
Dane_nowe$Popl = ifelse(is.na(Dane_nowe$Popl  ),
                       ave(Dane_nowe$Popl   , FUN = function(x) mean(x, na.rm = TRUE)),
                       Dane_nowe$Popl   )
Dane_nowe$`t_1-19`  = ifelse(is.na(Dane_nowe$`t_1-19`   ),
                        ave(Dane_nowe$`t_1-19`   , FUN = function(x) mean(x, na.rm = TRUE)),
                        Dane_nowe$`t_1-19`   )
Dane_nowe$`t_5-9` = ifelse(is.na(Dane_nowe$`t_5-9`   ),
                        ave(Dane_nowe$`t_5-9`    , FUN = function(x) mean(x, na.rm = TRUE)),
                        Dane_nowe$`t_5-9`    )
Dane_nowe$Income = ifelse(is.na(Dane_nowe$Income    ),
                           ave(Dane_nowe$Income    , FUN = function(x) mean(x, na.rm = TRUE)),
                           Dane_nowe$Income    )
Dane_nowe$Schooling = ifelse(is.na(Dane_nowe$Schooling   ),
                          ave(Dane_nowe$Schooling    , FUN = function(x) mean(x, na.rm = TRUE)),
                          Dane_nowe$Schooling    )
```


Sprawdzanie współliniowości.
Działanie kodu:
Ten kod tworzy nową macierz "matrix_nowy" z danymi "Dane_nowe" bez pierwszej kolumny.
Następnie oblicza macierz wartości własnych "matrix_eigen_nowy" jako iloczyn transponowanej
macierzy "matrix_nowy" i "matrix_nowy". W końcowym kroku wartości pierwszej wartości własnej
dzielone są przez wszystkie wartości własne, a następnie wynik jest pierwiastkowany.
Wyniki powyżej 30 pokazują brak współliniowości.
```{r}
matrix_nowy <- as.matrix(Dane_nowe[,-1])

matrix_eigen_nowy <- eigen(t(matrix_nowy) %*% matrix_nowy)
matrix_eigen_nowy$val

sqrt(matrix_eigen_nowy$val[1]/matrix_eigen_nowy$val)
```


Kod tworzy nowy model regresji liniowej "Model_nowy" z zmienną objaśnianą "Life" i kilkoma
zmiennymi objaśniającymi: "Adult_M", "Infant_D", "H_B", "Measles", "BMI", "Under_D", "Polio",
"Dipht", "H/A", "GDP", "Popl", "t_1-19", "t_5-9", "Income", "Schooling". Dane są wczytywane z data
frame'u "Dane_nowe". W końcowym kroku jest wyświetlany podsumowanie modelu regresji
liniowej "Model_nowy".
```{r}
Model_nowy <- lm(Life~Adult_M+Infant_D+H_B+Measles+BMI+Under_D+Polio+Dipht+`H/A`+GDP+Popl+`t_1-19`+`t_5-9`+Income+Schooling,data=Dane_nowe)
summary(Model_nowy)
```

Użycie metody “backward”, aby ustalić najlepszy model.
```{r}
Model_nowy_backward<-step(lm(Life~Adult_M+Infant_D+H_B+Measles+BMI+Under_D+Polio+Dipht+`H/A`+GDP+Popl+`t_1-19`+`t_5-9`+Income+Schooling,data=Dane_nowe),direction="backward")
summary(Model_nowy_backward)
```


Finalny wynik jest bardzo optymistyczny, ponieważ wynik R-squared wynosi 0.8726 (zmienność
oczekiwanej długości życia jest wyjaśniony w 87% przez model), a “Adjusted R-squared" wynosi
0.8675.
```{r}
Model_nowy <- Model_nowy_backward
summary(Model_nowy)
```


Sprawdzenie outlierów oraz stworzenie nowego modelu z usunietymi wartościami odstającymi.
```{r}
cooks_dis <- cooks.distance(Model_nowy)
plot(cooks_dis,ylab="Cooks distances")
Model_nowy_no_outliers <-lm(Life~Adult_M+Infant_D+H_B+Under_D+`H/A`+`t_1-19`+Income,data=Dane_nowe,subset=(cooks_dis<max(cooks_dis)))
```

```{r}
summary(Model_nowy_no_outliers)
```


```{r}
summary(Model_nowy)
```


Sprawdzenie czy rozkład jest normalny za pomocą Testu Shapiro. W przypadku “Model_nowy”
model nie ma rozkładu normalnego. Natomiast w modelu “Model_nowy_no_outliers” p-value
wynosi ponad 0.05, oznacza to, że istnieje rozkład normalny.
```{r}
shapiro.test(Model_nowy$res)
```

```{r}
shapiro.test(Model_nowy_no_outliers$res)
```

Na końcu porównałem moje wszystkie modele

“Model_nowy” ma lepszy “R-squared” niż “Model” - 0.72 < 0.87.
“Model_nowy” ma lepszy “Adjusted R-squared” niż “Model” - 0.71 < 0.86.
“Model_nowy” ma lepsze zmienne o wartości “p-value” mniejszych niż 0.05, niż “Model”:
* “Model” trzy wartości z przedziału 0 – 0,001
* “Model_nowy” cztery wartości z przedziału 0 – 0,001
* “Model” trzy wartości z przedziału 0,001 – 0,01
* “Model_nowy” trzy wartości z przedziału 0,001 – 0,01
* “Model” jedną wartość z przedziału 0,01 – 0,05
* “Model_nowy” jedną wartość z przedziału 0,01 – 0,05
* “Model” jedną wartość z przedziału 0,05 – 0,1
* “Model_nowy” zero wartości z przedziału 0,05 – 0,1
```{r}
summary(Model)
```

```{r}
summary(Model_nowy)
```


“Model_nowy_no_outliers” ma lepszy “R-squared” niż “Model_no_outliers” - 0.73 < 0.87.
“Model_nowy_no_outliers” ma lepszy “Adjusted R-squared” niż “Model_no_outliers” - 0.72 < 0.87.
“Model_nowy_no_outliers” ma lepsze zmienne o wartości “p-value” mniejszych niż 0.05, niż
“Model_no_outliers”:
* “Model_no_outliers” pięć wartości z przedziału 0 – 0,001
* “Model_nowy_no_outliers” sześć wartości z przedziału 0 – 0,001
* “Model_no_outliers” jedną wartość z przedziału 0,001 – 0,01
* “Model_nowy_no_outliers” jedną wartość z przedziału 0,001 – 0,01
* “Model_no_outliers” jedną wartość z przedziału 0,01 – 0,05
* “Model_nowy_no_outliers” jedną wartość z przedziału 0,01 – 0,05
* “Model_no_outliers” zero wartości z przedziału 0,05 – 0,1
* “Model_nowy_no_outliers” zero wartości z przedziału 0,05 – 0,1
* “Model_no_outliers” ma jedną wartość z przedziału 0,1 – 1
```{r}
summary(Model_no_outliers)
```

```{r}
summary(Model_nowy_no_outliers)
```


W tym etapie z ciekawości użyłem metody “Machine Learning”, aby zobaczyć jakie wyniki mogę
uzyskać działając na moich danych. Dokonałem podziału danych na część “test”, którą będę testować
na podstawie części “training”. Podział jest 80% dla “training” i 20% dla “test” z całości danych.
Zainstalowałem pakiet “caTools”, oraz go uruchomiłem za pomocą funkcji “library”. Następnie
uruchomienie funkcji “set.seed”, która odpowiada za generowanie losowych liczb. Funkcja
“sample.split”, która podzieliła moją bazą danych według ustalonego wcześniejszego podziału.
Kod przedstawia:
* Pierwsza linia - ładowanie biblioteki caTools
* Druga linia - ustawianie seeda losowego na wartość 123
* Trzecia linia - dzielenie danych na zbiór treningowy i testowy z proporcją 80/20
* Czwarta linia - tworzenie zbioru treningowego na podstawie danych i dzielenia
* Piąta linia - tworzenie zbioru testowego na podstawie danych i dzielenia
```{r}
library(caTools)
set.seed(123)
split = sample.split(Dane$Life, SplitRatio = 0.8)
training_set = subset(Dane, split == TRUE)
test_set = subset(Dane, split == FALSE)
```


Stworzenie modelu składającego z bazy danych “training_set”.
Kod przedstawia:
* Pierwsza linia - tworzenie modelu regresji liniowej na zbiorze treningowym, gdzie zmienna objaśniana jest Life a pozostałe zmienne są uwzględniane jako zmienne objaśniające
* Druga linia - wyświetlenie podsumowania modelu
```{r}
regressor = lm(formula = Life ~ .,
               data = training_set)

summary(regressor)
```


Stworzyłem przewidziane y, dla “regressor”
Kod przedstawia:
* Pierwsza linia - prognozowanie wartości Life na zbiorze testowym
* Druga linia - wyświetlenie prognozowanych wartości
```{r}
y_pred = predict(regressor, newdata = test_set)
y_pred
```


Stworzenie “training_set_nowy” i “test_set_nowy” na podstawie “Dane_nowe”, według tych
samych zasad.
```{r}
split_nowy = sample.split(Dane_nowe$Life, SplitRatio = 0.8)
training_set_nowy = subset(Dane_nowe, split == TRUE)
test_set_nowy = subset(Dane_nowe, split == FALSE)
```


Stworzenie modelu regresji liniowej “regressor_nowy” na zbiorze treningowym
“training_set_nowy”, gdzie zmienna objaśniana jest Life a pozostałe zmienne są uwzględniane jako
zmienne objaśniające
```{r}
regressor_nowy = lm(formula = Life ~ .,
               data = training_set_nowy)
```


Porównałem dwa modele.
“regressor_nowy” ma lepszy “R-squared” niż “regressor” - 0.71 < 0.87.
“regressor_nowy” ma lepszy “Adjusted R-squared” niż “regressor” - 0.69 < 0.86.
```{r}
summary(regressor_nowy)
```

```{r}
summary(regressor)
```


Prognozowanie wartości Life na zbiorze testowym “test_set_nowy” i modelu “regressor_nowy”.
```{r}
y_pred_nowy = predict(regressor_nowy, newdata = test_set_nowy)
y_pred_nowy
```


Porównanie “y_pred” i “y_pred_nowy” z “Life”.

1. “y_pred_nowy” jest bardziej przybliżony, różnica 0,45

2. “y_pred” jest bardziej przybliżony, różnica 2,37

3. “y_pred_nowy” jest bardziej przybliżony, różnica 2,77

4. “y_pred_nowy” jest bardziej przybliżony, różnica 0,19

5. “y_pred_nowy” jest bardziej przybliżony, różnica 0,53

6. “y_pred_nowy” jest bardziej przybliżony, różnica 0,25

7. “y_pred” jest bardziej przybliżony, różnica 4,95

8. “y_pred_nowy” jest bardziej przybliżony, różnica 1,72

9. “y_pred” jest bardziej przybliżony, różnica 1,16

10. “y_pred” jest bardziej przybliżony, różnica 0,75

11. “y_pred_nowy” jest bardziej przybliżony, różnica 0,13

12. “y_pred_nowy” jest bardziej przybliżony, różnica 5,48

13. “y_pred” jest bardziej przybliżony, różnica 5,78

14. “y_pred_nowy” jest bardziej przybliżony, różnica 3,38

15. “y_pred_nowy” jest bardziej przybliżony, różnica 0,19

16. “y_pred” jest bardziej przybliżony, różnica 0,39

17. “y_pred_nowy” jest bardziej przybliżony, różnica 0,8

18. “y_pred_nowy” jest bardziej przybliżony, różnica 1,18

19. “y_pred_nowy” jest bardziej przybliżony, różnica 2,83

20. “y_pred_nowy” jest bardziej przybliżony, różnica 2,79

21. “y_pred_nowy” jest bardziej przybliżony, różnica 0,20

22. “y_pred_nowy” jest bardziej przybliżony, różnica 1,73

23. “y_pred” jest bardziej przybliżony, różnica 0,55

24. “y_pred_nowy” jest bardziej przybliżony, różnica 1,2

25. “y_pred” jest bardziej przybliżony, różnica 2,42

26. “y_pred_nowy” jest bardziej przybliżony, różnica 1,13

27. “y_pred” jest bardziej przybliżony, różnica 0,20

28. “y_pred_nowy” jest bardziej przybliżony, różnica 20,22, anomalia

29. “y_pred_nowy” jest bardziej przybliżony, różnica 2,37

30. “y_pred” jest bardziej przybliżony, różnica 0,72

31. “y_pred_nowy” jest bardziej przybliżony, różnica 1,19

32. “y_pred” jest bardziej przybliżony, różnica 1,44

33. “y_pred” jest bardziej przybliżony, różnica 2,52

34. “y_pred_nowy” jest bardziej przybliżony, różnica 1,65

35. “y_pred” jest bardziej przybliżony, różnica 0,75

36. “y_pred” jest bardziej przybliżony, różnica 1,95

37. “y_pred_nowy” jest bardziej przybliżony, różnica 4,93

“y_pred_nowy” miał lepsze przybliżenie wyników w 23/37. W punkcie 28 doszło do anomalii, a
różnica wyniku przypadku “y_pred_nowy” okazało się oddalone od wartości ze zbioru testującej w
20,22, a “y_pred” w 46,02.
```{r}
y_pred = predict(regressor, newdata = test_set)
y_pred
```


```{r}
y_pred_nowy = predict(regressor_nowy, newdata = test_set_nowy)
y_pred_nowy
```